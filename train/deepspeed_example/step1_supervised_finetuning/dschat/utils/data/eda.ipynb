{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc099a4",
   "metadata": {},
   "source": [
    "# Tokenizer Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd8d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e85ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 34133\n",
      "First sample: {'messages': [{'content': 'Always respond with an emoji at the end', 'role': 'system'}, {'content': 'Can you help me draft a tweet about the beautiful sunset I saw today at the beach? I want to include a sense of tranquility and inspiration in the message.', 'role': 'user'}, {'content': '\"Embraced by the tranquil whisper of the waves, I watched as the sky turned into a canvas of warm hues. A beautiful sunset at the beach today, painting a picture of inspiration and serenity. 🌅\"', 'role': 'assistant'}, {'content': \"That's a beautiful tweet, thank you! Can you now show me how to post it on Twitter?\", 'role': 'user'}, {'content': \"Sure! Here are the steps:\\n\\n1. Open the Twitter app or website. \\n2. Click on the 'Tweet' button (it's a blue circle with a feather in it).\\n3. Copy and paste the tweet I crafted into the text box that appears.\\n4. When you're ready, click the 'Tweet' button to post it.\\n\\nRemember, Twitter has a character limit of 280 characters per tweet. Enjoy tweeting! 😊\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "from transformers import AutoTokenizer\n",
    "total_datasets = dict()\n",
    "for dataset_name in get_dataset_config_names(\"HuggingFaceTB/smoltalk\"):\n",
    "    if dataset_name == \"all\":\n",
    "        continue  # Skip the 'all' dataset as it is not a specific dataset\n",
    "    try:\n",
    "        dataset = load_dataset(\"HuggingFaceTB/smoltalk\", dataset_name, split=\"train\")\n",
    "        total_datasets[dataset_name] = len(dataset)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {dataset_name}: {e}\")\n",
    "# dataset = load_dataset(\"HuggingFaceTB/smoltalk\", name='all', split=\"train\")\n",
    "\n",
    "print(\"Number of samples in the dataset:\", len(dataset))\n",
    "print(\"First sample:\", dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d4774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4902fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 409537/409537 [00:32<00:00, 12795.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smol-magpie-ultra - Total input length: 409951800\n",
      "smol-magpie-ultra - Total output length: 183492630\n",
      "smol-magpie-ultra - Total length: 593444430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 34424/34424 [00:01<00:00, 21840.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smol-constraints - Total input length: 2670828\n",
      "smol-constraints - Total output length: 4518128\n",
      "smol-constraints - Total length: 7188956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 53342/53342 [00:01<00:00, 26814.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smol-rewrite - Total input length: 9819005\n",
      "smol-rewrite - Total output length: 7651217\n",
      "smol-rewrite - Total length: 17470222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 96356/96356 [00:03<00:00, 25789.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smol-summarize - Total input length: 38215806\n",
      "smol-summarize - Total output length: 9147688\n",
      "smol-summarize - Total length: 47363494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 83144/83144 [00:03<00:00, 27671.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apigen-80k - Total input length: 41063414\n",
      "apigen-80k - Total output length: 4945778\n",
      "apigen-80k - Total length: 46009192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 2260/2260 [00:00<00:00, 2724.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everyday-conversations - Total input length: 351451\n",
      "everyday-conversations - Total output length: 78421\n",
      "everyday-conversations - Total length: 429872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 30400/30400 [00:00<00:00, 32065.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore-instruct-rewriting - Total input length: 1750141\n",
      "explore-instruct-rewriting - Total output length: 879541\n",
      "explore-instruct-rewriting - Total length: 2629682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 3547/3547 [00:03<00:00, 983.49 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longalign - Total input length: 36463804\n",
      "longalign - Total output length: 653041\n",
      "longalign - Total length: 37116845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 47500/47500 [00:01<00:00, 30488.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metamathqa-50k - Total input length: 3011574\n",
      "metamathqa-50k - Total output length: 8623503\n",
      "metamathqa-50k - Total length: 11635077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 106147/106147 [00:03<00:00, 34699.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numina-cot-100k - Total input length: 9446620\n",
      "numina-cot-100k - Total output length: 45826019\n",
      "numina-cot-100k - Total length: 55272639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 95000/95000 [00:03<00:00, 28535.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openhermes-100k - Total input length: 14797027\n",
      "openhermes-100k - Total output length: 20917171\n",
      "openhermes-100k - Total length: 35714198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 48127/48127 [00:01<00:00, 31994.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self-oss-instruct - Total input length: 5709826\n",
      "self-oss-instruct - Total output length: 9207413\n",
      "self-oss-instruct - Total length: 14917239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 34133/34133 [00:01<00:00, 19297.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemchats-30k - Total input length: 13091122\n",
      "systemchats-30k - Total output length: 7081342\n",
      "systemchats-30k - Total length: 20172464\n"
     ]
    }
   ],
   "source": [
    "total_map_datasets = dict()\n",
    "for dataset_name, num_samples in total_datasets.items():\n",
    "    try:\n",
    "        dataset = load_dataset(\"HuggingFaceTB/smoltalk\", dataset_name, split=\"train\")\n",
    "        def process_batch(batch):\n",
    "            inputs = [tokenizer.apply_chat_template(msgs[:-1]) for msgs in batch['messages']]\n",
    "            outputs = [tokenizer.apply_chat_template(msgs[-1:]) for msgs in batch['messages']]\n",
    "            input_lens = [len(i) for i in inputs]\n",
    "            output_lens = [len(o) for o in outputs]\n",
    "            return {\n",
    "                \"input\": inputs,\n",
    "                \"output\": outputs,\n",
    "                \"input_len\": input_lens,\n",
    "                \"output_len\": output_lens,\n",
    "                \"total_len\": [il + ol for il, ol in zip(input_lens, output_lens)],\n",
    "            }\n",
    "        map_dataset = dataset.map(\n",
    "            process_batch,\n",
    "            batched=True,\n",
    "            num_proc=64,  # 시스템에 맞게 조정\n",
    "        )\n",
    "        total_map_datasets[dataset_name] = map_dataset  # 이미 total_datasets에 있음\n",
    "\n",
    "        total_input_length = sum(map_dataset['input_len'])\n",
    "        total_output_length = sum(map_dataset['output_len'])\n",
    "        print(f\"{dataset_name} - Total input length: {total_input_length}\")\n",
    "        print(f\"{dataset_name} - Total output length: {total_output_length}\")\n",
    "\n",
    "        print(f\"{dataset_name} - Total length: {sum(map_dataset['total_len'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {dataset_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ec7a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smol-magpie-ultra': Dataset({\n",
       "     features: ['messages', 'category', 'difficulty', 'quality', 'reward_model_score', 'conversation_tokens', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 409537\n",
       " }),\n",
       " 'smol-constraints': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 34424\n",
       " }),\n",
       " 'smol-rewrite': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 53342\n",
       " }),\n",
       " 'smol-summarize': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 96356\n",
       " }),\n",
       " 'apigen-80k': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 83144\n",
       " }),\n",
       " 'everyday-conversations': Dataset({\n",
       "     features: ['full_topic', 'messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 2260\n",
       " }),\n",
       " 'explore-instruct-rewriting': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 30400\n",
       " }),\n",
       " 'longalign': Dataset({\n",
       "     features: ['tokens', 'messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 3547\n",
       " }),\n",
       " 'metamathqa-50k': Dataset({\n",
       "     features: ['type', 'messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 47500\n",
       " }),\n",
       " 'numina-cot-100k': Dataset({\n",
       "     features: ['source', 'messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 106147\n",
       " }),\n",
       " 'openhermes-100k': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 95000\n",
       " }),\n",
       " 'self-oss-instruct': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 48127\n",
       " }),\n",
       " 'systemchats-30k': Dataset({\n",
       "     features: ['messages', 'input', 'output', 'input_len', 'output_len', 'total_len'],\n",
       "     num_rows: 34133\n",
       " })}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_map_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8105db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smol-magpie-ultra - Max length: 8956\n",
      "smol-constraints - Max length: 1525\n",
      "smol-rewrite - Max length: 860\n",
      "smol-summarize - Max length: 3276\n",
      "apigen-80k - Max length: 2882\n",
      "everyday-conversations - Max length: 309\n",
      "explore-instruct-rewriting - Max length: 545\n",
      "longalign - Max length: 28505\n",
      "metamathqa-50k - Max length: 2679\n",
      "numina-cot-100k - Max length: 3739\n",
      "openhermes-100k - Max length: 5041\n",
      "self-oss-instruct - Max length: 1894\n",
      "systemchats-30k - Max length: 3180\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, map_dataset in total_map_datasets.items():\n",
    "    try:\n",
    "        # total_input_length = sum(map_dataset['input_len'])\n",
    "        # total_output_length = sum(map_dataset['output_len'])\n",
    "        # print(f\"{dataset_name} - Total input length: {total_input_length}\")\n",
    "        # print(f\"{dataset_name} - Total output length: {total_output_length}\")\n",
    "\n",
    "        print(f\"{dataset_name} - Max length: {max(map_dataset['total_len'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {dataset_name}: {e}\")\n",
    "# total_map_datasets['smol-magpie-ultra']['total_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b02434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input length: 586341555\n",
      "Total output length: 303040887\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851915b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mncai/foundation_model_smoltalk_ko_translate\", name='default', split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f7bfb",
   "metadata": {},
   "source": [
    "# PrimeIntellect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c380a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PrimeIntellect/SYNTHETIC-2-SFT-verified\", name='default', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f79e9c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|██████████| 104913/104913 [00:06<00:00, 15440.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input length: 36047851\n",
      "Total output length: 85360359\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    inputs = [tokenizer.apply_chat_template(msgs[:-1]) for msgs in batch['messages']]\n",
    "    outputs = [tokenizer.apply_chat_template(msgs[-1:]) for msgs in batch['messages']]\n",
    "    input_lens = [len(i) for i in inputs]\n",
    "    output_lens = [len(o) for o in outputs]\n",
    "    return {\n",
    "        \"input\": inputs,\n",
    "        \"output\": outputs,\n",
    "        \"input_len\": input_lens,\n",
    "        \"output_len\": output_lens,\n",
    "        \"total_len\": [il + ol for il, ol in zip(input_lens, output_lens)],\n",
    "    }\n",
    "map_dataset = dataset.map(\n",
    "    process_batch,\n",
    "    batched=True,\n",
    "    num_proc=64,  # 시스템에 맞게 조정\n",
    ")\n",
    "# total_map_datasets[dataset_name] = num_samples  # 이미 total_datasets에 있음\n",
    "\n",
    "total_input_length = sum(map_dataset['input_len'])\n",
    "total_output_length = sum(map_dataset['output_len'])\n",
    "print(f\"Total input length: {total_input_length}\")\n",
    "print(f\"Total output length: {total_output_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b7bcbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemchats-30k - Max length: 12859\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dataset_name} - Max length: {max(map_dataset['total_len'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a92fde18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input length: 9386\n",
      "Max output length: 12616\n",
      "Max Total length: 12859\n"
     ]
    }
   ],
   "source": [
    "max_input_length = max(map_dataset['input_len'])\n",
    "max_output_length = max(map_dataset['output_len'])\n",
    "map_dataset = map_dataset.map(\n",
    "    lambda x: {\"total_len\": [input_len + output_len for input_len, output_len in zip(x['input_len'], x['output_len'])]},\n",
    "    batched=True,\n",
    "    num_proc=64,  # 시스템에 맞게 조정\n",
    ")\n",
    "max_total_length = max(map_dataset['total_len'])\n",
    "print(f\"Max input length: {max_input_length}\")\n",
    "print(f\"Max output length: {max_output_length}\")\n",
    "print(f\"Max Total length: {max_total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4425145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104913"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(map_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d300e2",
   "metadata": {},
   "source": [
    "# MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9c3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e105336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepSpeedExamples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
